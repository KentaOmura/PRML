{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測分布を最尤推定とベイズ推定による実装を行う。\n",
    "\n",
    "**■検証材料**\n",
    "\n",
    "データの生成は$sin(x)$からガウス分布に従って生成されているとする。\n",
    "生成された、データ$x$とそれに対応する$t$を使用して、多項式を使用して当てはめたとする。\n",
    "tは平均が多項式の値に等しく、精度が$\\beta$のガウス分布に従うとする。\n",
    "この分布を使用して、ベイズ推定、最尤推定の両者での訓練データを入力した後の予測分布についてみていく。\n",
    "\n",
    "まず、必要なモジュールと定義を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "\n",
    "BAYES = 1 #ベイズ推定\n",
    "MLE = 0   #最尤推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に多項式モデルを生成するクラスを作成する。\n",
    "多項式としては、以下の簡単な多項式とする。\n",
    "$y(x) = x^1+x^2+・・・x^M$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Polynomial:\n",
    "    \"\"\"\n",
    "    本クラスは簡単な多項式を生成するクラス。\n",
    "    多項式としては、1+x^1+x^2・・・x^(D-1) の多項式を提供します。（Dは設定した次元数）\n",
    "    使用方法\n",
    "    クラス生成時に次元数を引数に与えるだけで、関数取得時に設定した次元数の多項式を生成します。\n",
    "    取得する時のメソッドはgetFunction()です。\n",
    "    引数として、ベクトルもしくは、1つのパラメータを入力する必要があります。\n",
    "    \"\"\"\n",
    "    def __init__(self, diag):\n",
    "        self.diag = diag\n",
    "    def getFunction(self, x):\n",
    "        func = np.array([x**i for i in range(self.diag)])\n",
    "        return func.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に予測分布を算出するクラスを作成する。\n",
    "予測分布を算出するクラスでは、最尤推定での予測分布モデルを算出するか、ベイズ推定で予測分布モデルを算出するかを選ぶ事ができる。\n",
    "\n",
    "ここで、ベイズ推定を使用する際に、事後分布を使用して予測分布を算出するが、この事後分布の算出過程を確認する。\n",
    "前提としては、事前分布として$p(\\boldsymbol{w}|\\alpha) = N(\\boldsymbol{w}|\\boldsymbol{0},\\alpha^{-1}I)$を用いる。\n",
    "また、尤度関数は$p(\\boldsymbol{t}|\\boldsymbol{x}, \\boldsymbol{w}, \\beta) = \\prod_{n}^{N} N(t_n|y(\\boldsymbol{w},x_n), \\beta^{-1})$であるので、\n",
    "事後分布は以下の式で算出できる。\n",
    "\n",
    "$p(\\boldsymbol{w}|\\boldsymbol{x},\\boldsymbol{t},\\alpha, \\beta) = p(\\boldsymbol{t}|\\boldsymbol{x}, \\boldsymbol{w}, \\beta)p(\\boldsymbol{w}|\\alpha)$\n",
    "\n",
    "事前分布と尤度関数がガウス分布なので、事後分布もガウス分布となる。\n",
    "ここで、一般の多変量ガウス分布の指数部分に着目する。\n",
    "\n",
    "$-\\frac{\\boldsymbol{1}}{2}(\\boldsymbol{\\mu}-\\boldsymbol{w})^T\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}-\\boldsymbol{w})$\n",
    "\n",
    "式を展開し、整理すると以下の式となる。\n",
    "\n",
    "$-\\frac{\\boldsymbol{1}}{2}(\\boldsymbol{\\mu}^T\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu} - 2\\boldsymbol{w}^T\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu} + \\boldsymbol{w}^T\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{w})$\n",
    "\n",
    "ガウス分布は制御パラメータである、平均と精度が算出できれば、導出できるので、この式で係数比較を用いて平均と精度を算出していく。\n",
    "\n",
    "本題。\n",
    "事前分布と尤度関数の積を取った後の指数部分に着目すると以下の式となる。\n",
    "\n",
    "$-\\frac{\\alpha}{2}\\boldsymbol{w}^T\\boldsymbol{w} - \\frac{\\beta}{2}(\\boldsymbol{t} - \\boldsymbol{\\Phi}\\boldsymbol{w})^T(\\boldsymbol{t} - \\boldsymbol{\\Phi}\\boldsymbol{w})$\n",
    "\n",
    "整理すると、以下の式となる。\n",
    "\n",
    "$-\\frac{1}{2}(\\boldsymbol{w}^T(\\alpha I+\\beta\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi})\\boldsymbol{w}- 2\\beta\\boldsymbol{w}^T\\boldsymbol{\\Phi}^T\\boldsymbol{t} + \\beta\\boldsymbol{t}^T\\boldsymbol{t})$\n",
    "\n",
    "よって、係数比較を行うと、精度と平均は以下の式となる。\n",
    "$\\boldsymbol{\\Sigma}^{-1} = \\alpha I+\\beta\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}$\n",
    "$\\boldsymbol{\\mu} = \\beta\\boldsymbol{\\Sigma}\\boldsymbol{\\Phi}^T\\boldsymbol{t}$\n",
    "\n",
    "上記事後分布を使用して、予測分布をベイズ推定した式は以下となる。\n",
    "\n",
    "$p(t|x,\\boldsymbol{t},\\boldsymbol{x}) = \\int p(t|x,\\boldsymbol{w})p(\\boldsymbol{w}|\\boldsymbol{t},\\boldsymbol{x})d\\boldsymbol{w}$\n",
    "\n",
    "予測分布もガウス分布となり、平均と分散は以下の式となる。\n",
    "$m(x) = \\beta \\boldsymbol{\\phi}(x)^T\\boldsymbol{\\Sigma}\\sum_{n=1}^{N}\\boldsymbol{\\phi}(x_n)t_n$\n",
    "$s^2(x) = \\beta^{-1} + \\boldsymbol{\\phi}(x)^T\\boldsymbol{\\Sigma}\\boldsymbol{\\phi}(x)$\n",
    "\n",
    "これらと最尤推定による平均と分散の算出結果を用いて、予測分布の実装を以下に行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictedDist:\n",
    "    \"\"\"\n",
    "    本クラスは予測分布を提供するクラス。\n",
    "    tの精度パラメータβと、ベイズ推定で用いる事前分布の精度パラメータαを入力する。\n",
    "    その後、訓練データを本クラスのメソッドfit()で提供する事で、学習を行う。\n",
    "    predict()メソッドを使用する事で、学習結果と入力されたxを用いて、目的変数tの予測分布のパラメータを提供する。\n",
    "    αとβはデフォルト値として、α=5*10**(-3) β=11.1とする。\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=5*10**(-3), beta=11.1, mode = MLE):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.mode = mode\n",
    "\n",
    "    # 訓練データから学習を行う。\n",
    "    def fit(self, X, t):\n",
    "        if self.mode == MLE:\n",
    "            #最尤推定の場合は、訓練データから予測分布のパラメータを算出する。最小二乗法を解く必要がある。\n",
    "            pass\n",
    "        else:\n",
    "            self.accuracy = self.alpha * np.identity(X.shape[1]) + self.beta*X.T @ X\n",
    "            self.mu = self.beta * np.linalg.inv(self.accuracy) @ X.T @ t\n",
    "    \n",
    "    # 予測分布を算出する\n",
    "    def predict(self, X):\n",
    "        y = X.dot(self.mu)\n",
    "        y_var = 1 / self.beta + X.T @ np.linalg.inv(self.accuracy) @ X\n",
    "        y_std = np.sqrt(y_var)\n",
    "        return y, y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、データの生成関数と、main関数を実装して、\n",
    "上記クラスを用いて、予測分布を図示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 5 is different from 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36988/2187911632.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36988/2187911632.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36988/3465030939.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# 予測分布を算出する\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0my_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0my_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 5 is different from 100)"
     ]
    }
   ],
   "source": [
    "def createData(f,low, high, size):\n",
    "    x = np.random.uniform(low=low, high=high, size=size)\n",
    "    t = f(x) + np.random.normal(loc=0, scale=1/11.1, size=size)\n",
    "    return x,t\n",
    "\n",
    "def main():\n",
    "    x_train, t_train = createData(lambda x : np.sin(2*np.pi*x), 0 , 1, 20)\n",
    "\n",
    "    # 5次元の多項式を使用する\n",
    "    X = Polynomial(5).getFunction(x_train)\n",
    "\n",
    "    # 訓練データを用いて、学習を行う\n",
    "    model = PredictedDist(mode=BAYES)\n",
    "    model.fit(X,t_train)\n",
    "\n",
    "    x = np.linspace(0,1,100)\n",
    "    y, y_std = model.predict(x)\n",
    "    \n",
    "    print(y,y_std)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ab94a47810cca1c455de50c2d6c2a92526c30cfd8eee14c27cfd98c02b7c639"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
