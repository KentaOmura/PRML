###1章のまとめ

本章では、
機械学習の基礎となる確率論と決定理論、情報理論について解説されている。

ここでは簡単に内容についてまとめる。

<span style="font-size: 150%;">**■確率論**</span>
確率論は、不確実な事象に対して操作する枠組みを与える理論。
不確実なものとは何か？
→結果が決定していない、揺らぎのある事象の事。
　例えば、サイコロを振った後の目の数など。

**■前段**
ここで、以降の議論をする前に確率変数について触れる。
確率変数とは、ある事象に対して、ある値を返す関数の事である。
確率変数を定義する事で、現実世界の事象を自分で定めた数値と紐づける事で、
扱いが便利になる。

**■本題**
★重要なのは以下の定理（何故この定理が成立するかは面積で考えると分かりやすい）
・確率の乗法定理
&emsp;$p(x,y) = p(x|y)p(y)$
・確率の加法定理
&emsp;$p(x) = \sum_{n=1}p(x,y_n)$

上記の定理から以下の関係式が得られる
&emsp;$p(x|y) =$ <span style="font-size: 150%;">$\frac{p(x,y)}{p(y)}$</span>

$p(x,y) = p(y,x)$の関係から上記の関係式のyとxを入れ替え、
同時確率については、確率の乗法定理を使用する事でベイズの定理が導出できる。

&emsp;$p(y|x) =$ <span style="font-size: 150%;">$\frac{p(x|y)p(y)}{p(x)}$</span>

上記の意味は、
$y$の分布$p(y)$がデータ$x$の情報を得る事で、$x$を考慮した上で
$y$の分布を更新するという意味になる。

最後に、独立性について述べる。
・独立性
2つの確率変数を考えた時に、それぞれが独立した確率変数の場合
即ち、それぞれの確率変数が関係性をもっていない時。
（1つの観測値を見ても、もう1つの確率に変わりがないという事）
よって以下の式が成立する。
&emsp;$p(x|y) = p(x)$

上記式より、2つの確率変数が独立の時に限り、確率の乗法定理は以下となる。
&emsp;$p(x,y) = p(x)p(y)$

---
**●指標**
不確実な事象を取り扱う上で、一定の指標を得たい時がある。
そこで、指標として、期待値と分散、共分散について考える。

・期待値
期待値とは、確率変数の取りうる平均値を表現する指標。
イメージとしては、確率を面積、確率変数を高さと考えて体積を求めているとイメージする。
確率の総和は1になるので、面積の総和は1になる事を踏まえると、
各体積の総和は、面積1の高さがある一定の値を持つ1つの立方体になる。
この高さを期待値と呼ぶ。または、平均とも呼ぶ。
式
$E[x] \equiv \sum_{n=1}x_np(x_n)$

・分散
分散とは、観測され得る確率変数が、期待値からどれだけ離れているのかを表現する指標。
離れている事を、期待値から確率変数を引く事で表現する。
引いた後の値はもちろん確率変数となる。導出過程で確率変数が出ているから。
なので、一定の評価を得る為に、期待値を取る。
しかし、そうすると、期待値から確率変数を引いた時に負の数も現れるので、
正と負で打消し合い正しい分散値が取得できない。
その為、期待値から確率変数を引く時に、二乗を取る。
（絶対値という手もあるが、今後の計算を考えると二乗の方が都合がいい。）
よって以下の式で分散を導出できる。
$V[x] \equiv E[(x-E[x])^2]$

・共分散
共分散とは、観測され得る異なる2つの確率変数の関係性を表現する為の指標。
★分散と名前が似ているけど、得られる意味は異なっているので注意★
2つの確率変数をそれぞれ$x, y$と置き、それぞれの平均値を$μ, ν$と置く。
その上で共分散を以下のように定義する。
$Cov[x,y] \equiv E[(x-μ)(y-ν)]$
意味としては、$x$が大きい(小さい)と$y$も大きく(小さく)なる傾向がある事や、
$x$が大きく(小さく)ても$y$が大きい（小さい）の傾向が無い事を知る事ができる。

>補足
>期待値と分散の式で()ではなく、[]を使用しているのは、関数ではなく汎関数の為。
>関数は入力として数を入れて、数を出力する物。
>汎関数は入力として関数を入れて、数を出力する物。
>確率変数は関数だから、期待値と分散、共分散は汎関数。
---

ここで、上記の指標の関係式を考える。
・期待値
確率変数を定数倍した時の期待値の関係式は以下の通り。
$E[ax] = aE[x]$
>理由
>左辺は確率変数をa倍した状態で各体積を足す事を意味しており、
>右辺は体積を求めた後a倍する事を意味しているので、同じ意味となっている。

確率変数に定数を加えた時の期待値の関係式は以下の通り。
$E[x+a] = a+E[x]$
>理由
>左辺は確率変数にaを加えて各体積を足す事を意味しており、
>右辺は各体積の総和を求めた後、aを足す事を意味しているので、同じ意味となっている。

2つの（独立な）確率変数の和の期待値の関係式は以下の通り。
$E[x+y] = E[x] + E[y]$
>理由
>左辺は2つの確率変数を足した後、各体積を足す事を意味しており、
>右辺はそれぞれの確率変数の体積を求めた後で、足し合わせているので同じ意味となっている。

2つの独立な確率変数の積の期待値の関係式は以下の通り。
$E[xy] = E[x]E[y]$
>理由
>$E[xy] = \sum_{i}\sum_{j}x_iy_jp(x=x_i,y=y_j)$と記載する事ができ
>確率の乗法定理から以下の式に変換できる。
>$E[xy] = \sum_{i}x_ip(x=x_i)\sum_{j}y_jp(y=y_j)$と記載する事ができる。
>すると、右辺は各確率変数の期待値の積になっている事がわかる。
>よって、$E[xy] = E[x]E[y]$
>※確率変数が独立でない場合については特に性質の良い関係式は得られない。

・分散
分散の定義から別の表現を行う。その関係式は以下の通り。
$V[x] = E[x^2] - E[x]^2$
>理由
>左辺の式は定義から、$E[x]=μ$と置くと、$V[x]=E[(x-μ)^2]$
>ここで、$E[(x-μ)^2]$の中身を展開する。
>すると、$E[(x^2-2xμ+μ^2)]$となり、期待値の和の関係性、定数倍の関係性から
>$E[(x^2)]-2μE[x]+μ^2$となる。ここで、$E[x]=μ$の関係式から、
>$V[x] = E[x^2] - E[x]^2$となる。

確率変数を定数倍した時の分散の関係式は以下の通り。
$V[ax] = a^2V[x]$
>理由
>左辺の式は定義から、$E[x]=μ$と置くと、$V[ax]=E[(ax-aμ)^2]$
>ここで、$E[(ax-aμ)^2]$について注目する。
>aは共通しているので、括りだすと$E[a^2(x-μ)^2]$が得られる。<br>よって、期待値の関係式から$a^2E[(x-μ)^2]$となる。
>よって、$V[ax] = a^2V[x]$

確率変数に定数を加えた時の分散の関係式は以下の通り。
$V[x+a] = V[x]$
>理由
>左辺の式は定義から、$E[x]=μ$と置くと、$V[a+x]=E[(a+x-a-μ)^2]$
>よって、右辺は$E[(x-μ)^2]$となり、$V[x]$そのものとなっている。

2つの独立な確率変数の和の分散の関係式は以下の通り。
$V[x+y] = V[x]+V[y]$
>理由
>左辺の式は定義から、$E[x]=μ, E[y] = ν$と置くと、<br>$V[x+y]=E[(x+y-μ-ν)^2]$
>ここで、$E[(x+y-μ-ν)^2]$について注目する。
>中身を展開すると、$(x-μ)^2+2(x-μ)(y-ν)+(y-ν)^2$となる。<br>ここで期待値の和の関係式から以下の式なる。
>$E[(x-μ)^2]+E[2(x-μ)(y-ν)]+E[(y-ν)^2]$となる。<br>ここで$E[2(x-μ)(y-ν)]$について着目する。
>式から、これは共分散の定義となっている。共分散は独立の時に0となるので、真ん中の項は消える。
>従って、$E[(x-μ)^2]+E[(y-ν)^2]$となり、これは分散の定義式となっているので、
>$V[x+y] = V[x]+V[y]$が得られる。

・共分散
共分散の定義から別の表現を行う。その関係式は以下の通り。
$Cov[x,y] = E[xy]-E[x]E[y]$
>理由
>左辺の式は定義から、$E[x]=μ, E[y] = ν$と置くと、<br>$Cov[x,y]=E[(x-μ)(y-ν)]$
>ここで、$E[(x-μ)(y-ν)]$の中身を展開する。
>すると、$E[(xy-xν-μy+μν)]$となり、期待値の和の関係性、定数倍の関係性から
>$E[xy]-νE[x]-μE[y]+μν$となる。ここで、$E[x]=μ, E[y] = ν$の関係式から、
>$E[xy]-E[x]E[y]$となる。

2つの確率変数をそれぞれ定数倍した時の共分散の関係式は以下の通り。
$Cov[ax,by] = abCov[x,y]$
>理由
>左辺の式は定義から、$E[x]=μ, E[y] = ν$と置くと、<br>$Cov[ax,by]=E[axby]-E[ax]E[by]$
>期待値の和と定数倍の関係式から、
>$Cov[ax,by]=abE[xy]-abE[x]E[y]$となる。abで括ると、以下の式となる。
>$Cov[ax,by] = abCov[x,y]$

2つの確率変数にそれぞれ定数を加えた時の共分散の関係式は以下の通り。
$Cov[a+x,b+y] = Cov[x,y]$
>理由
>左辺の式は定義から、$E[x]=μ, E[y] = ν$と置くと、<br>$Cov[a+x,b+y]=E[(a+x)(b+y)]-E[a+x]E[b+y]$
>$E[(a+x)(b+y)]$の中身を展開すると、$E[ab+ay+xb+xy]$となる。
>期待値の積と和及び、定数和の関係式から以下の式となる。
>$Cov[a+x,b+y]=ab+aE[y]+bE[x]+E[xy]-(a+E[x])(b+E[y])$<br>整理すると、
>$Cov[a+x,b+y]=E[xy]-E[x]E[y]$となり、右辺は共分散の定義となっている。

2つ確率変数が独立の時の共分散の関係式は以下の通り。
$Cov[x,y] = 0$
>理由
>左辺の式は定義から、$E[x]=μ, E[y] = ν$と置くと、<br>$Cov[x,y]=E[xy]-E[x]E[y]$
>x,yが独立の時は、期待値の積の関係式から、
>$Cov[x,y]=E[x]E[y]-E[x]E[y]$となる。従って、右辺は0となる。
