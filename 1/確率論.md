###1章のまとめ

本章では、
機械学習の基礎となる確率論と決定理論、情報理論について解説されている。

ここでは簡単に内容についてまとめる。

<span style="font-size: 150%;">**■確率論**</span>
確率論は、不確実な事象に対して操作する枠組みを与える理論。
不確実なものとは何か？
→結果が決定していない、揺らぎのある事象の事。
　例えば、サイコロを振った後の目の数など。

**■前段**
確率の議論をする為に、確率空間を定義する。
確率空間とは？
$(Ω,F,p)$で表現される空間の事で、$Ω$は考えられる事象全体を表現し、
$p$はある事象が発生した時の面積を表現する。
$F$は難しいので省略する。一旦は$F$は性質の良い事象を集めた物と考える。
例えば、ルーレットを考える。
ルーレットを回した時に、針が数値と数値の中間で止まった時の事象などを省いた事象の集まりと考える。
$p$で求めている面積の事象も$F$の部分集合の面積を求めている。
（$Ω$はルーレットを回した時に針が中間で止まる事象も含められている。）
→ただし、基本は意識していない。厳密すぎるので・・・
　だから、ざっくり$Ω$と$F$は同じって考えてもいいと思う。数学警察に怒られそうだけど。。。

また、$p(Ω)=1$が成立する。

※確率を$p = \frac{事象の数}{全体事象の総和}$で表現されるが、これは大数の法則から表現される。

次に確率変数を導入する。
確率変数とは、ある事象に対して、ある値を返す関数の事である。
確率変数を定義する事で、現実世界の事象を自分で定めた数値と紐づける事で、
扱いが便利になる。

**■本題**
★重要なのは以下の定理（何故この定理が成立するかは面積で考えると分かりやすい）
・確率の乗法定理
&emsp;$p(x,y) = p(x|y)p(y)$
・確率の加法定理
&emsp;$p(x) = \sum_{n=1}p(x,y_n)$

上記の定理から以下の関係式が得られる
&emsp;$p(x|y) =$ <span style="font-size: 150%;">$\frac{p(x,y)}{p(y)}$</span>

$p(x,y) = p(y,x)$の関係から上記の関係式のyとxを入れ替え、
同時確率については、確率の乗法定理を使用する事でベイズの定理が導出できる。

&emsp;$p(y|x) =$ <span style="font-size: 150%;">$\frac{p(x|y)p(y)}{p(x)}$</span>

上記の意味は、
$y$の分布$p(y)$がデータ$x$の情報を得る事で、$x$を考慮した上で
$y$の分布を更新するという意味になる。

最後に、独立性について述べる。
・独立性
2つの確率変数を考えた時に、それぞれが独立した確率変数の場合
即ち、それぞれの確率変数が関係性をもっていない時。
（1つの観測値を見ても、もう1つの確率に変わりがないという事）
よって以下の式が成立する。
&emsp;$p(x|y) = p(x)$

上記式より、2つの確率変数が独立の時に限り、確率の乗法定理は以下となる。
&emsp;$p(x,y) = p(x)p(y)$

---
**●指標**
不確実な事象を取り扱う上で、一定の指標を得たい時がある。
そこで、指標として、期待値と分散、共分散について考える。

・期待値
期待値とは、確率変数の取りうる平均値を表現する指標。
イメージとしては、確率を面積、確率変数を高さと考えて体積を求めているとイメージする。
確率の総和は1になるので、面積の総和は1になる事を踏まえると、
各体積の総和は、面積1の高さがある一定の値を持つ1つの立方体になる。
この高さを期待値と呼ぶ。または、平均とも呼ぶ。
式
$E[x] \equiv \sum_{n=1}x_np(x_n)$

・分散
分散とは、観測され得る確率変数が、期待値からどれだけ離れているのかを表現する指標。
離れている事を、期待値から確率変数を引く事で表現する。
引いた後の値はもちろん確率変数となる。導出過程で確率変数が出ているから。
なので、一定の評価を得る為に、期待値を取る。
しかし、そうすると、期待値から確率変数を引いた時に負の数も現れるので、
正と負で打消し合い正しい分散値が取得できない。
その為、期待値から確率変数を引く時に、二乗を取る。
（絶対値という手もあるが、今後の計算を考えると二乗の方が都合がいい。）
よって以下の式で分散を導出できる。
$V[x] \equiv E[(x-E[x])^2]$

・共分散
共分散とは、観測され得る異なる2つの確率変数の関係性を表現する為の指標。
★分散と名前が似ているけど、得られる意味は異なっているので注意★
2つの確率変数をそれぞれ$x, y$と置き、それぞれの平均値を$μ, ν$と置く。
その上で共分散を以下のように定義する。
$Cov[x,y] \equiv E[(x-μ)(y-ν)]$
意味としては、$x$が大きい(小さい)と$y$も大きく(小さく)なる傾向がある事や、
$x$が大きく(小さく)ても$y$が大きい（小さい）の傾向が無い事を知る事ができる。

>補足
>期待値と分散の式で()ではなく、[]を使用しているのは、関数ではなく汎関数の為。
>関数は入力として数を入れて、数を出力する物。
>汎関数は入力として関数を入れて、数を出力する物。
>確率変数は関数だから、期待値と分散、共分散は汎関数。
---

ここで、上記の指標の関係式を考える。
・期待値
確率変数を定数倍した時の期待値の関係式は以下の通り。
$E[ax] = aE[x]$
>理由
>左辺は確率変数をa倍した状態で各体積を足す事を意味しており、
>右辺は体積を求めた後a倍する事を意味しているので、同じ意味となっている。

確率変数に定数を加えた時の期待値の関係式は以下の通り。
$E[x+a] = a+E[x]$
>理由
>左辺は確率変数にaを加えて各体積を足す事を意味しており、
>右辺は各体積の総和を求めた後、aを足す事を意味しているので、同じ意味となっている。

2つの（独立な）確率変数の和の期待値の関係式は以下の通り。
$E[x+y] = E[x] + E[y]$
>理由
>左辺は2つの確率変数を足した後、各体積を足す事を意味しており、
>右辺はそれぞれの確率変数の体積を求めた後で、足し合わせているので同じ意味となっている。

2つの独立な確率変数の積の期待値の関係式は以下の通り。
$E[xy] = E[x]E[y]$
>理由
>$E[xy] = \sum_{i}\sum_{j}x_iy_jp(x=x_i,y=y_j)$と記載する事ができ
>確率の乗法定理から以下の式に変換できる。
>$E[xy] = \sum_{i}x_ip(x=x_i)\sum_{j}y_jp(y=y_j)$と記載する事ができる。
>すると、右辺は各確率変数の期待値の積になっている事がわかる。
>よって、$E[xy] = E[x]E[y]$
>※確率変数が独立でない場合については特に性質の良い関係式は得られない。

・分散
分散の定義から別の表現を行う。その関係式は以下の通り。
$V[x] = E[x^2] - E[x]^2$
>理由
>左辺の式は定義から、$E[x]=μ$と置くと、$V[x]=E[(x-μ)^2]$
>ここで、$E[(x-μ)^2]$の中身を展開する。
>すると、$E[(x^2-2xμ+μ^2)]$となり、期待値の和の関係性、定数倍の関係性から
>$E[(x^2)]-2μE[x]+μ^2$となる。ここで、$E[x]=μ$の関係式から、
>$V[x] = E[x^2] - E[x]^2$となる。

確率変数を定数倍した時の分散の関係式は以下の通り。
$V[ax] = a^2V[x]$
>理由
>左辺の式は定義から、$E[x]=μ$と置くと、$V[ax]=E[(ax-aμ)^2]$
>ここで、$E[(ax-aμ)^2]$について注目する。
>aは共通しているので、括りだすと$E[a^2(x-μ)^2]$が得られる。<br>よって、期待値の関係式から$a^2E[(x-μ)^2]$となる。
>よって、$V[ax] = a^2V[x]$

確率変数に定数を加えた時の分散の関係式は以下の通り。
$V[x+a] = V[x]$
>理由
>左辺の式は定義から、$E[x]=μ$と置くと、$V[a+x]=E[(a+x-a-μ)^2]$
>よって、右辺は$E[(x-μ)^2]$となり、$V[x]$そのものとなっている。

2つの独立な確率変数の和の分散の関係式は以下の通り。
$V[x+y] = V[x]+V[y]$
>理由
>左辺の式は定義から、$E[x]=μ, E[y] = ν$と置くと、<br>$V[x+y]=E[(x+y-μ-ν)^2]$
>ここで、$E[(x+y-μ-ν)^2]$について注目する。
>中身を展開すると、$(x-μ)^2+2(x-μ)(y-ν)+(y-ν)^2$となる。<br>ここで期待値の和の関係式から以下の式なる。
>$E[(x-μ)^2]+E[2(x-μ)(y-ν)]+E[(y-ν)^2]$となる。<br>ここで$E[2(x-μ)(y-ν)]$について着目する。
>式から、これは共分散の定義となっている。共分散は独立の時に0となるので、真ん中の項は消える。
>従って、$E[(x-μ)^2]+E[(y-ν)^2]$となり、これは分散の定義式となっているので、
>$V[x+y] = V[x]+V[y]$が得られる。

・共分散
共分散の定義から別の表現を行う。その関係式は以下の通り。
$Cov[x,y] = E[xy]-E[x]E[y]$
>理由
>左辺の式は定義から、$E[x]=μ, E[y] = ν$と置くと、<br>$Cov[x,y]=E[(x-μ)(y-ν)]$
>ここで、$E[(x-μ)(y-ν)]$の中身を展開する。
>すると、$E[(xy-xν-μy+μν)]$となり、期待値の和の関係性、定数倍の関係性から
>$E[xy]-νE[x]-μE[y]+μν$となる。ここで、$E[x]=μ, E[y] = ν$の関係式から、
>$E[xy]-E[x]E[y]$となる。

2つの確率変数をそれぞれ定数倍した時の共分散の関係式は以下の通り。
$Cov[ax,by] = abCov[x,y]$
>理由
>左辺の式は定義から、$E[x]=μ, E[y] = ν$と置くと、<br>$Cov[ax,by]=E[axby]-E[ax]E[by]$
>期待値の和と定数倍の関係式から、
>$Cov[ax,by]=abE[xy]-abE[x]E[y]$となる。abで括ると、以下の式となる。
>$Cov[ax,by] = abCov[x,y]$

2つの確率変数にそれぞれ定数を加えた時の共分散の関係式は以下の通り。
$Cov[a+x,b+y] = Cov[x,y]$
>理由
>左辺の式は定義から、$E[x]=μ, E[y] = ν$と置くと、<br>$Cov[a+x,b+y]=E[(a+x)(b+y)]-E[a+x]E[b+y]$
>$E[(a+x)(b+y)]$の中身を展開すると、$E[ab+ay+xb+xy]$となる。
>期待値の積と和及び、定数和の関係式から以下の式となる。
>$Cov[a+x,b+y]=ab+aE[y]+bE[x]+E[xy]-(a+E[x])(b+E[y])$<br>整理すると、
>$Cov[a+x,b+y]=E[xy]-E[x]E[y]$となり、右辺は共分散の定義となっている。

2つ確率変数が独立の時の共分散の関係式は以下の通り。
$Cov[x,y] = 0$
>理由
>左辺の式は定義から、$E[x]=μ, E[y] = ν$と置くと、<br>$Cov[x,y]=E[xy]-E[x]E[y]$
>x,yが独立の時は、期待値の積の関係式から、
>$Cov[x,y]=E[x]E[y]-E[x]E[y]$となる。従って、右辺は0となる。

---
**●確率密度と確率分布**
今までお話は確率変数が離散の場合について考えてきた。
確率変数が連続の時は、上記の指標や確率の乗法定理、和の定理は単純に
$\sum_{}$から$\int$に変更すれば良い。
但し、確率変数xが離散の時に確率を表現していた$p(x)$についての解釈は変えなければいけない。
離散から連続になると、考えられる場合の数は有限から無限に変わる。
その為、確率の定義により、特定の事象の面積は0となる。ある事象を$x$と置くと、$p(x)=0$。
しかし、$\sum_{n}p(x_n)=1$は成立する。
この事から、1つ1つの事象の確率は0なのに、総和したら1となる。ちょっとした矛盾が発生する。
連続の場合は、事象を微小区間でまとめる事（量子化）で、この矛盾を解決する。
この微小区間を$Δx$とすると、確率を$p(x)Δx$で定義する。この時、$p(x)$を確率密度関数と呼ぶ。
何故確率密度関数と呼ぶかというと、$Δx$は距離を表しており、$p(x)Δx$を確率（面積）とするなら
$p(x)$は密度を表現している事になるから。
全体の確率(面積)$P(x)$は$P(x) = \int_{-∞}^{∞}p(x)dx$となる。
左辺を$x$について微分すると、$\frac{dP(x)}{dx} = p(x)$となる。

確率密度関数は確率の定義より以下の関係式を満たす。
・$\int_{-∞}^{∞}p(x)dx$ = 1
・$p(x) \geqq 0$

次に、確率分布について簡単に述べる。
確率分布とは、事象が起きる確率を表現した分布の事。（そのまんま～）
離散の場合で、サイコロの確率分布を以下に記載する。
|     | P(x) | 
| --- | :--- | 
| 1   | 1/6  | 
| 2   | 1/6  | 
| 3   | 1/6  | 
| 4   | 1/6  | 
| 5   | 1/6  | 
| 6   | 1/6  | 
上記のように、考えられる事象についての確率を右に並べた表を分布と呼ぶ。
では、連続な確率変数の場合はどうなるのか。
上記のように考えると、すべての確率は0になるので、ここでも確率密度を使用して分布を考える。
以下に確率密度として、ガウス分布を使用した分布を記載する。
```python
import numpy as np
import matplotlib.pyplot as plt

x = np.arange(-10,10,0.1)
# 標準正規分布
y = 1/(np.sqrt(2*np.pi*1)) * np.exp(-1/2*np.power(x-0,2))

plt.plot(x,y)
plt.show()
```
![ガウス分布](C:/work/数学/Prml上/PRML/PRML/1/ガウス分布.png) 

---
**●ガウス分布**
ここで確率分布で最も重要と言っても過言ではない分布であるガウス分布を紹介する。
ガウス分布は解析的に性質が良いのと、あらゆるデータの分布がこのガウス分布に従っている事から
機械学習では頻繁に使用される。

ガウス分布は以下のように定義される。
$N(x|μ,σ^2) = \frac{1}{\sqrt(2πσ^2)}\exp(-\frac{(x-μ)^2}{2σ^2})$
上記で注目する箇所は$\exp(-\frac{(x-μ)^2}{2σ^2})$。
係数部分は分布の総和を1にする為の規格化係数だから。
この時、ガウス分布のパラメータである$μ$を平均、$σ^2$を分散と呼び、$σ$を標準偏差と呼ぶ。

規格化係数の確認。
規格化係数の総和を省いた形で計算を行う
$\int_{-∞}^{∞}\exp(-\frac{(x-μ)^2}{2σ^2})dx$
上記において、$(x-μ)=z$と置く。
$(x-μ)=z$の両辺を$x$で微分すると$dz = dx$となる。
また、$\lim_{x \to \infty}z =  \infty$であり、$\lim_{x \to -\infty}z =  -\infty$。
よって、上記の式は以下の式で記載しなおす事ができる。
$\int_{-∞}^{∞}\exp(-\frac{z^2}{2σ^2})dz$
これは、ガウス積分の形になっているので、積分すると、$\sqrt(2\piσ^2)$
よって、規格化する為には、$\frac{1}{\sqrt(2\piσ^2)}$を係数とすれば良い。

ここからは、ガウス分布の性質について確認していく。


ガウス分布の期待値はどうなる？
定義より、
$E[x] = \int_{-∞}^{∞}\frac{1}{\sqrt(2πσ^2)}\exp(-\frac{(x-μ)^2}{2σ^2})xdx$と記載できる。
$\frac{(x-μ)}{\sigma}=z$と置き、両辺の$x$についての微分を取ると$\frac{1}{\sigma}dx = dz$となる。
ここで、与式を以下のように変形する。
$E[x] = \int_{-∞}^{∞}\frac{1}{\sqrt(2π\sigma^2)}\exp(-\frac{(x-μ)^2}{2σ^2})\frac{(x-μ)}{\sigma}\sigma dx + μ$
これにより、変換ができるので、変換を行う。
$E[z] = \frac{1}{\sqrt(2π)}\int_{-∞}^{∞}\exp(-\frac{z^2}{2})zdz + μ$
ここで、部分積分を行う
$E[z] = -\frac{1}{\sqrt(2π\sigma^2)}\int_{-∞}^{∞}\exp(-\frac{z^2}{2})^′dz + μ$
計算すると、以下の式となる。
$E[z] = -\frac{1}{\sqrt(2π\sigma^2)}[\exp(-\frac{z^2}{2})]^{\infty}_{-\infty} + 
μ$
ここで、右辺の第一項は0となるから、期待値は$μ$となる。


ガウス分布の分散はどうなる？
まず、二次のモーメントを算出した後で、$V[x] = E[x^2] - E[x]^2$を使用して求める作戦を取る。
$E[x^2] = \int_{-∞}^{∞}\frac{1}{\sqrt(2πσ^2)}\exp(-\frac{(x-μ)^2}{2σ^2})x^2dx$と記載
ここで、以下のように変形する。
$E[x^2] = \int_{-∞}^{∞}\frac{1}{\sqrt(2πσ^2)}\exp(-\frac{(x-μ)^2}{2σ^2})((x-μ)^2 + 2xμ-μ^2)dx$－①
ここで、$\frac{(x-μ)}{\sigma}=z$と置き、両辺の$x$についての微分を取ると$\frac{1}{\sigma}dx = dz$となる。
①に代入すると、以下の式となる。
$E[z^2] = \int_{-∞}^{∞}\frac{1}{\sqrt(2πσ^2)}\exp(-\frac{z^2}{2})(z\sigma)^2\sigma dz + 2μ^2-μ^2$
整理すると、
$E[z^2] = \frac{\sigma^2}{\sqrt(2π)}\int_{-∞}^{∞}\exp(-\frac{z^2}{2})z^2 dz + 2μ^2-μ^2$
同じく部分積分を行うと、最終的に以下の式となる。
$E[x^2] = \sigma^2 + \mu^2$
従って、分散は
$V[x] = \sigma^2 + \mu^2 - \mu^2$より、$V[x] = \sigma^2$

---
**■推定**
ここからは推定方法について紹介していく。
やりたいことは、観測されたデータからデータが生成された分布を推定したい。

ある確率変数の集合$\boldsymbol{x} = (x_1,x_2,・・・,x_N)^T$が同じ分布から独立に観測されたとする。
観測された分布をガウス分布と置くと、データ集合の確率は確率乗法定理より
$p(\boldsymbol{x}|\mu,\sigma^2) = \prod_{n=1}^{N}p(x_n|\mu,\sigma)$となる。
$\mu, \sigma^2$の関数とすると、これはガウス分布に対する尤度関数と呼ぶ。
このデータ集合から、確率分布のパラメータを決める方法として、
尤度関数を最大とするパラメータを求める事である。これを最尤推定と呼ぶ。
尤度関数の両辺の対数を取ると、以下の式となる。

$\ln p(\boldsymbol{x}|\mu,\sigma^2) = -\frac{N}{2}\ln (2\pi\sigma^2) -\frac{1}{2\sigma^2}\sum_{n=1}^{N}(x_n - \mu)^2$

$\mu$の関数として見ると、上に凸な関数となるので、両辺を$\mu$で微分して0となる箇所が
最大値となる。

両辺を$\mu$で微分すると以下の式になる。
$\frac{\partial }{\partial \mu}\ln p = \frac{1}{\sigma^2}\sum_{n=1}^{N}(x_n-\mu)$ となる。
この式が0となる時の$\mu$の値は以下となる。

$\mu_{ML} = \frac{1}{N}\sum_{n=1}^{N}x_n$
これをサンプル平均と呼ぶ。

同様にして$\sigma^2$について最大化させる。

$\ln p(\boldsymbol{x}|\mu,\sigma^2) = -\frac{N}{2}\ln (2\pi\sigma^2) -\frac{1}{2\sigma^2}\sum_{n=1}^{N}(x_n - \mu)^2$

上記の式を$\sigma^2$で微分する。

$\frac{\partial }{\partial \sigma^2}\ln p(\boldsymbol{x}|\mu,\sigma^2) = -\frac{N}{2\sigma^2} +\frac{1}{2\sigma^4}\sum_{n=1}^{N}(x_n - \mu)^2$
この式が0となる時の$\sigma^2$の値は以下となる。

$\sigma^2_{ML} = \frac{1}{N}\sum_{n=1}^{N}(x_n-\mu_{ML})^2$
これをサンプル分散と呼ぶ。


上記のサンプル平均とサンプル分散には観測された揺らぎのデータの値が入っている為、
サンプル平均、分散共に確率変数となる。
従って、期待値を取る事でこの揺らぎを止める。
$E[\mu_{ML}] = \int \mu_{ML}p(\boldsymbol{x})d\boldsymbol{x} = \mu$

$E[\sigma^2_{ML}] = \int \sigma^2_{ML}p(\boldsymbol{x})d\boldsymbol{x}$
これはややこしい。
地道に解く。（一旦$E$で記載しなおす）
$右辺 = \frac{1}{N}E[\sum_{n}(x_n - \mu_{ML})^2]$
$\hspace{23pt}=\frac{1}{N}\sum_{n} E[x_n^2 -2\mu_{ML}x_n + \mu_{ML}^2]$
$\hspace{23pt}=\frac{1}{N}\sum_{n} (E[x_n^2] -\frac{2}{N}E[\sum_{m}x_mx_n] + E[\frac{1}{N^2}(\sum_{m}x_m)^2])$
$\hspace{23pt}=\frac{1}{N}\sum_{n} (\mu^2+\sigma^2 -\frac{2}{N}\sum_{m}E[x_mx_n] + E[\frac{1}{N^2}(\sum_{m}x_m)^2])$
$\hspace{23pt}=\frac{1}{N}\sum_{n} (\mu^2+\sigma^2 -\frac{2}{N}(\sigma^2+\mu^2 +(N-1)\mu^2)+ \frac{1}{N^2}E[(\sum_{m}x_m)^2])$
$\hspace{23pt}=\frac{1}{N}\sum_{n} (\mu^2+\sigma^2 -\frac{2}{N}(\sigma^2+\mu^2 +(N-1)\mu^2)+ \frac{1}{N}((\sigma^2 + \mu^2)+(N-1)\mu^2))$
$\hspace{23pt}=\frac{1}{N}\sum_{n} (\sigma^2 -\frac{1}{N}\sigma^2)$
$\hspace{23pt}=\frac{N-1}{N}\sigma^2$

よって、サンプル平均の期待値は母平均と一致するが、
サンプル分散の分散は母分散の$\frac{N-1}{N}$されており、過小評価されている。
（母分散より広がりが少ない。）
これは、サンプル分散の平均からの差を算出する際に、サンプル平均を使用している為。
サンプル分散は取得したデータからの差分しか求める事ができず、また平均がサンプル平均としているので、
どうしても母分散と比べると過小評価されてしまう。
因みに、サンプル分散の評価の際に母平均を使用する事ができるのであれば、サンプル分散の期待値は母分散に一致する。
推定する際は、もちろん母平均なんて知らない事が多いので、
母分散になるように以下の不変分散で推定を行う。
$\tilde{V} = \frac{N}{N-1}\sigma^2_{ML}$

上記より、最尤推定での推定の考えは、
得られるデータは変動するが、生成モデルを決めるパラメータは不変の考えを主軸とし、
データからモデルを制御しているパラメータを1つに絞って推定しているのがわかる。
この考えの逆はどうなるのか？
どういうことかというと、得られたデータは不変で、推定したパラメータは変動するという考え。
つまり、最初に推定したパラメータが観測されたデータによって、推定するパラメータがどんどん変動していくという事。
これが、ベイズ推定！
ここで、ベイズの定理を思い出す。式は以下の通り。
$p(x|y) \propto p(y|x)p(x)$ ※分母は規格化係数の為、省略した。
上記の式は、生成モデルのパラメータ$x$の推定に対して、
パラメータ$x$を固定した時のデータ$y$の分布との積を取る事で、
データ$y$が観測された上での生成モデルのパラメータ$x$の推定を修正する式となっている。

でも実際知りたいのは、データが観測された時の生成モデルのパラメータの分布ではなく、
次にどういったデータが観測され得るのかを推定したい。（予測分布って呼ばれます。）
**※ここは大事！機械学習のモチベーションは全てここにある！！**

予測分布を最尤推定で求めるパターンと、ベイズ推定で求める2パターンで紹介する。

例として、観測データ$x$と、それに対応する観測データ$t$が存在しており、
観測データ$x$から対応する$t$の分布を求める事とする。

ここで予測分布をガウス分布に従うと仮定する。
また、平均は多項式である$y(\boldsymbol{w},x)$とし、精度を$\beta$とする。
すると、以下の式で記載する事ができる。
$p(t|x, \boldsymbol{w}, \beta) = N(t|y(\boldsymbol{w},x), \beta^{-1})$
ここで、観測データが独立に$N$個観測された状況を考える。
$\boldsymbol{x} = (x_1, x_2, ・・・, x_N)$、$\boldsymbol{t} = (t_1, t_2, ・・・, t_N)$

まず、最尤推定法を用いて予測分布を算出する。
同時に上記のデータが観測された時の尤度関数は以下の通り
$p(\boldsymbol{t}|\boldsymbol{x}, \boldsymbol{w}, \beta) = \prod_{n}^{N} N(t_n|y(\boldsymbol{w},x_n), \beta^{-1})$

両辺対数を取ると、以下の式となる。

$\ln p(\boldsymbol{t}|\boldsymbol{x}, \boldsymbol{w}, \beta) = -\frac{N}{2}\ln (2\pi) + \frac{N}{2}\ln \beta -\frac{\beta}{2}\sum_{n}^{N}(t_n -y(\boldsymbol{w},x_n))^2$

上記で$\boldsymbol{w}$に関しての項は、$-\frac{\beta}{2}\sum_{n}^{N}(t_n -y(\boldsymbol{w},x_n))^2$となる。$\ln p(\boldsymbol{t}|\boldsymbol{x}, \boldsymbol{w}, \beta)$が最大とする為には、
$-\frac{\beta}{2}\sum_{n}^{N}(t_n -y(\boldsymbol{w},x_n))^2$を最大にする必要がある。
上記の式で正の定数を掛けても$\boldsymbol{w}$の最大の位置は変わらないので、$\frac{1}{\beta}$を掛ける。
また、符号を逆転させると、最小二乗法の式が導出できる。

$\frac{1}{2}\sum_{n}^{N}(t_n -y(\boldsymbol{w},x_n))^2$

この式を$\boldsymbol{w}$で微分して、$0$と置くことで$\boldsymbol{w}$の値を推定する事ができる。

次に、$\beta$についても同様に最尤推定法で推定する。

$\ln p(\boldsymbol{t}|\boldsymbol{x}, \boldsymbol{w}, \beta) = -\frac{N}{2}\ln (2\pi) + \frac{N}{2}\ln \beta -\frac{\beta}{2}\sum_{n}^{N}(t_n -y(\boldsymbol{w},x_n))^2$

上記の式から$\beta$についての項だけを取り出すと、以下となる。

$\frac{N}{2}\ln \beta -\frac{\beta}{2}\sum_{n}^{N}(t_n -y(\boldsymbol{w},x_n))^2$

上記の式を$\beta$で微分して、$0$と置くことで、$\beta$を推定する事ができる。
これで、最尤推定法により、予測分布のパラメータ$\beta_{ML},\boldsymbol{w}_{ML}$を算出できたので、
予測分布は以下の式となる。

$p(t|x, \boldsymbol{w}_{ML}, \beta_{ML}) = N(t|y(\boldsymbol{w}_{ML},x), \beta^{-1}_{ML})$

次にベイズ推定での予測分布を算出する。
その為に、事前分布として以下の分布を用意する。

$p(\boldsymbol{w}|\alpha) = N(\boldsymbol{w}|\boldsymbol{0},\alpha^{-1}\boldsymbol{I}) = (\frac{\alpha}{2\pi})^{\frac{M+1}{2}}\exp (-\frac{\alpha}{2}\boldsymbol{w}^T\boldsymbol{w})$

$\alpha$は制度パラメータ、$M+1$は$M$次元の$\boldsymbol{w}$の要素の数である。
ベイズ推定を実施するには、尤度関数が必要であるが、上記の最尤推定法で出てきた尤度関数である。
この尤度関数と事前分布を使用すると、事後分布は以下の式で記載できる。

$p(\boldsymbol{w}|\boldsymbol{x},\boldsymbol{t},\alpha,\beta) \propto p(\boldsymbol{t}|\boldsymbol{x}, \boldsymbol{w}, \beta)p(\boldsymbol{w}|\alpha)$

(規格化係数は省略している為、$\propto$で記載している)

この事後分布を使用した予測分布は以下の式で記載できる。

$p(t|x,\boldsymbol{x},\boldsymbol{t}) = \int p(t|x,\boldsymbol{w})p(\boldsymbol{w}|\boldsymbol{t},\boldsymbol{x})d\boldsymbol{w}$

上記の式は、$\boldsymbol{w}$を$\boldsymbol{t},\boldsymbol{x}$を観測した時の事後分布と$\boldsymbol{w}$のパラメータを固定した時の$t$の尤度関数の積を$\boldsymbol{w}$の全場合を足し合わせた事になる。（周辺化）

上記を計算すると以下の予測分布となる。

$p(t|x,\boldsymbol{x},\boldsymbol{t}) = N(t|m(x),s^2(x))$

この時、$m(x), s^2(x)$は以下のような式となる。

$m(x) = \beta\boldsymbol{\phi}^T\boldsymbol{S}\sum_{n=1}^{N}\boldsymbol{\phi}(x_n)t_n$

$s(x)^2 = \beta^{-1} + \boldsymbol{\phi}(x)^T\boldsymbol{S}\boldsymbol{\phi}(x)$

行列$S$は以下の式となる。

$\boldsymbol{S}^{-1} = \alpha\boldsymbol{I} + \beta\sum_{n=1}^{N}\boldsymbol{\phi}(x_n)\boldsymbol{\phi}(x_n)^T$

同フォルダの「予測分布.ipynb」で実装を格納した。
